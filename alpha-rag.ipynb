{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "989a6efe-8918-433f-888d-7f88a94e44cf",
   "metadata": {},
   "source": [
    "# PROBLEM STATEMENT\n",
    "The primary objective of this work is to create a RAG pipeline over the `101 alpha formulaic book` to extract alpha number, expression and explanation. Utimately, this will serve as a basis for creating an end-to-end alpha agent that will discover alpha signals over a knowledge base, create its python implementation, perform backtesting and trade live if expected performance pass a satisfactory threshold.\n",
    "\n",
    "# TODO\n",
    "- Use the __ChatGrok model__ to increase inference speed.\n",
    "- Use more capable model to generate alpha information.\n",
    "\n",
    "# CHALLENGES\n",
    "- Sometimes the model is unable to generate the alpha information due to OutputParserException.\n",
    "- The alpha expression and the alpha number returned do not match what is in the document(Hallucination). At this time, it is entirely possible to posit that the alpha expression are not even contained in the document. Perhaps, they are generated from internal knowledge of the model.\n",
    "\n",
    "# POSSIBLE SOLUTIONS TO CHALLENGES\n",
    "- Use more advanced LLM and embeddings method. Perhaps, this may help address the hallucination issue. I am refraining from using extraction approach as long-term, It is expected that we would have a rich and large repositories of papers, documents with alpha information. Also, the improved understanding of LLM models with advanced maths would help incredibly in this regard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67400e0d-30f2-404a-bf67-d7e8119fec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Optional, add tracing in LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Alpha agent project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85064a5f-d5a5-49e9-bfce-906dcd485381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Pass in LANGCHAIN_API_KEY ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass(f\"Pass in {var}\")\n",
    "\n",
    "_set_if_undefined(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efc500eb-841d-4e13-93af-65e9dff201cf",
   "metadata": {},
   "source": [
    "## Ground an alpha retriever to document provided\n",
    "\n",
    "The goal of this work is to generate alpha expression and explanation based on the document provided. If response not relevant to document, we return not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b3c237-9a3a-44ed-b3f4-e00fa78474d3",
   "metadata": {},
   "source": [
    "Based on the workflow above, the following steps are followed:\n",
    "1. Based on a given `query`, we generate relevant documents.\n",
    "2. We then use a `binary score` to check whether each retrieved document is relevant or not.\n",
    "3. __If document is relevant__, we generate an answer. otherwise, we `re-write` the `query`.\n",
    "4. For the answer generated in 3, we check if the answer is grounded to the document(to reduce hallucination).\n",
    "5. __If no hallucination__, we then check if `answer` is relevant to the question. otherwise `repeat step 3`.\n",
    "6. __If answer is relevant to question__, return answer. otherwise, `repeat 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d2df39b-caa3-48e0-a521-8013cfb33d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries (UNCOMMENT below)\n",
    "#!pip install pypdf gpt4all langchain langchain-core langchain-community faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a80053e-15e7-41bb-84b8-a8c58963bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "local_llm = 'llama3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2123399e-7ddf-4f43-8ffc-531923cd0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "loader = PyPDFLoader(\"101-Alpha-Formula.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "doc_splits = splitter.split_documents(documents)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=GPT4AllEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "736f1c07-cd80-456a-bd8b-ba2305458b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing query to ensure no duplicate documents returned by retriever's get_relevant_documents method\n",
    "\n",
    "ALPHA_EXPRESSION_EXAMPLE = \"\"\"\n",
    "((rank(Sign(delta(IndNeutralize(((open * 0.868128) + (high * (1 - 0.868128))),\n",
    "IndClass.industry), 4.04545)))^Ts_Rank(correlation(high, adv10, 5.11456), 5.53756)) * -1)\n",
    "\"\"\"\n",
    "query = f\"Generate alpha information based on flow of funds strategy. (Example of alpha information: {ALPHA_EXPRESSION_EXAMPLE})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c61fd97-41e9-4434-a9ef-e75681e38a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c58c05-c1da-4718-901c-7df31ec57667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65449fa9-247c-403e-98ca-a9bab7600650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_duplicates(documents):\n",
    "    seen = set()\n",
    "    unique_docs = []\n",
    "    for doc in documents:\n",
    "        if doc.page_content not in seen:\n",
    "            unique_docs.append(doc)\n",
    "            seen.add(doc.page_content)\n",
    "    return unique_docs\n",
    "\n",
    "# Use the remove_duplicates function to remove duplicates from the retrieved documents\n",
    "unique_docs = remove_duplicates(docs)\n",
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d34d0e8-940e-4f73-8540-53af22098c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='A.1. Formulaic Expressions for Alphas \\nAlpha#1:  (rank(Ts_ArgMax(SignedPower(((returns < 0) ? stdde v(returns, 20) : close), 2.), 5)) - \\n0.5) \\nAlpha#2:  (-1 * correlation(rank(delta(log(volume), 2)), ran k(((close - open) / open)), 6)) \\nAlpha#3:  (-1 * correlation(rank(open), rank(volume), 10)) \\nAlpha#4:  (-1 * Ts_Rank(rank(low), 9)) \\nAlpha#5:  (rank((open - (sum(vwap, 10) / 10))) * (-1 * abs(r ank((close - vwap))))) \\nAlpha#6:  (-1 * correlation(open, volume, 10))', metadata={'source': '101-Alpha-Formula.pdf', 'page': 7})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4294bf21-cde6-48eb-b5b1-36797435386c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='* 0.96633) + (low * (1 - 0.96633))) - vwap) / (open  - ((high + low) / 2))), 11.4157), 6.72611)) * -1) \\nAlpha#67:  ((rank((high - ts_min(high, 2.14593)))^rank(correl ation(IndNeutralize(vwap, \\nIndClass.sector), IndNeutralize(adv20, IndClass.sub industry), 6.02936))) * -1) \\nAlpha#68:  ((Ts_Rank(correlation(rank(high), rank(adv15), 8.9 1644), 13.9333) < \\nrank(delta(((close * 0.518371) + (low * (1 - 0.5183 71))), 1.06157))) * -1)', metadata={'source': '101-Alpha-Formula.pdf', 'page': 11})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b74cfc5-c131-4d9d-9fff-47a3fca6c329",
   "metadata": {},
   "source": [
    "## Create a graph state\n",
    "\n",
    "Our state will be a `dict`, We can access through any graph `node` as `state[keys]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b91e873e-b14b-485d-8b74-ffeccf062d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Dict\n",
    "\n",
    "class AlphaRagState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the graph state of the alpha agent\n",
    "\n",
    "    Attributes:\n",
    "        keys: A dictionary where \n",
    "    \"\"\"\n",
    "    keys: Dict[str, any]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d349c7bd-520a-47d1-a94a-e190af7c803b",
   "metadata": {},
   "source": [
    "## Define nodes for our workflow\n",
    "Create the following nodes:\n",
    "1. retrieve\n",
    "2. grade_documents\n",
    "3. generate\n",
    "4. transform_query\n",
    "5. prepare_for_final_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd933e58-f85f-4f76-a987-58e33d511098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve node gets relevant documents based on a user query\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    print(\"Documents in context: \", docs)\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieves relevant documents\n",
    "\n",
    "    Args: \n",
    "        state (dict): current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to the state, documents, contains relevant documents to question \n",
    "    \"\"\"\n",
    "    print(\"-- RETRIEVING DOCUMENTS --\")\n",
    "    print(\"State: \", state)\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    relevant_docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "    return {\"keys\": { \"documents\": relevant_docs, \"question\": question}}\n",
    "    \n",
    "# grade_documents node\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECKING RELEVANCE---\")\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    documents = state_dict[\"documents\"]\n",
    "\n",
    "    # LLM\n",
    "    llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "    # prompt\n",
    "    prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \n",
    "    \n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\n",
    "     \n",
    "    Here is the retrieved document: \n",
    "    {document}\n",
    "    \n",
    "    Here is the user question: \n",
    "    {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm | JsonOutputParser()\n",
    "\n",
    "    # Score\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        binary_result = chain.invoke({\"question\": question, \"document\": d.page_content})\n",
    "        print(\"Score result: \", binary_result)\n",
    "        grade = binary_result[\"score\"]\n",
    "\n",
    "        print(\"Grade: \", grade)\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "\n",
    "    return {\"keys\": {\"documents\": filtered_docs, \"question\": question}}\n",
    "            \n",
    "# generate node for generating answer to questions\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    documents = state_dict[\"documents\"]\n",
    "\n",
    "    list_of_alpha_numbers = ['Alpha#1', 'Alpha#2', 'Alpha#3', 'Alpha#101']\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "    template= \"\"\"You are an assistant for question-answering tasks. \\n\n",
    "    Use the retrieved documents to answer the question. If you don't know the answer, just say that you don't know. \\n\n",
    "\n",
    "    Please provide an answer as a JSON with 3 keys: 'alpha_number', 'alpha_expression', and 'alpha_explanation'. \\n\n",
    "    Please ensure 'alpha_number' coincide with 'alpha_expression' as provided in the retrieved documents. \\n\n",
    "    Ensure that the 'alpha_explanation' is a description of the 'alpha_expression'. \\n\n",
    "\n",
    "    Here are examples of alpha numbers in the documents:\n",
    "    {list_of_alpha_numbers} \\n\n",
    "    \n",
    "    Here are 3 examples of alpha expression that can be extracted from documents:\n",
    "    ((-1 * rank((delta(close, 7) * (1 - rank(decay_linear((volume / adv20), 9)))))) * (1 + rank(sum(returns, 250)))) \\n\n",
    "    rank((-1 * ((1 - (open / close))^1))) \\n\n",
    "    (-1 * delta((((close - low) - (high - close)) / (close - low)), 9)) \\n\n",
    "     \n",
    "    Here are the retrieved documents: \n",
    "    {documents}\n",
    "    \n",
    "    Here is the user question: \n",
    "    {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"documents\", \"list_of_alpha_numbers\"],\n",
    "    )\n",
    "\n",
    "    # LLM\n",
    "    llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "    formatted_docs = format_docs(documents)\n",
    "\n",
    "    # Chain\n",
    "    rag_chain = prompt | llm | JsonOutputParser()\n",
    "\n",
    "    # Run\n",
    "    generation = rag_chain.invoke({\"documents\":formatted_docs, \"question\": question, \"list_of_alpha_numbers\": list_of_alpha_numbers})\n",
    "    \n",
    "    print(\"Generated response to alpha query: \", generation)\n",
    "    return {\n",
    "        \"keys\": {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "    }\n",
    "\n",
    "# transform query node, to regenerate query based on \n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORMING QUERY---\")\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    documents = state_dict[\"documents\"]\n",
    "\n",
    "    # Create a prompt template with format instructions and the query\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are generating alpha trading idea question / query that is well optimized for retrieval. \\n \n",
    "        Look at the input and try to reason about the underlying sematic intent / meaning. \\n \n",
    "        Here is the initial question:\n",
    "        \\n ------- \\n\n",
    "        {question} \n",
    "        \\n ------- \\n\n",
    "        Formulate an improved alpha trading idea question: \"\"\",\n",
    "        input_variables=[\"question\"],\n",
    "    )\n",
    "\n",
    "    # Grader\n",
    "    llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "    # Prompt\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "    better_question = chain.invoke({\"question\": question})\n",
    "\n",
    "    return {\"keys\": {\"documents\": documents, \"question\": better_question}}\n",
    "\n",
    "# prepare for final grade, \n",
    "def prepare_for_final_grade(state):\n",
    "    \"\"\"\n",
    "    Passthrough state for final grade.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): The current graph state\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---FINAL GRADE---\")\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    documents = state_dict[\"documents\"]\n",
    "    generation = state_dict[\"generation\"]\n",
    "\n",
    "    return {\n",
    "        \"keys\": {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e1a345-a80c-4842-b324-0d7d8f40cd3c",
   "metadata": {},
   "source": [
    "## Define edges for our workflow\n",
    "Create the following edges:\n",
    "1. decide_to_generate\n",
    "2. decide_generation_is_grounded_in_documents\n",
    "3. decide_generation_addresses_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9686cd96-2ca3-4f58-8a9b-fcdd67fbb1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state of the agent, including all keys.\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---DECIDE TO GENERATE OR TRANSFORM QUERY---\")\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    filtered_documents = state_dict[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\"---DECISION: TRANSFORM QUERY---\")\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def decide_generation_is_grounded_in_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state of the agent, including all keys.\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---GRADE GENERATION based on DOCUMENTS---\")\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    documents = state_dict[\"documents\"]\n",
    "    generation = state_dict[\"generation\"]\n",
    "\n",
    "    # LLM\n",
    "    llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing whether \n",
    "    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \n",
    "    single key 'score' and no preamble or explanation.\n",
    "    \n",
    "    Here are the facts:\n",
    "    {documents} \n",
    "\n",
    "    Here is the answer: \n",
    "    {generation}\n",
    "    \"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm | JsonOutputParser()\n",
    "\n",
    "    formatted_docs = format_docs(docs)\n",
    "\n",
    "    binary_result = chain.invoke({\"generation\": generation, \"documents\": formatted_docs})\n",
    "    grade = binary_result[\"score\"]\n",
    "\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: SUPPORTED, MOVE TO FINAL GRADE---\")\n",
    "        return \"grounded\"\n",
    "    else:\n",
    "        print(\"---DECISION: NOT SUPPORTED, GENERATE AGAIN---\")\n",
    "        return \"not grounded\"\n",
    "\n",
    "\n",
    "def decide_generation_addresses_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation addresses the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state of the agent, including all keys.\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    documents = state_dict[\"documents\"]\n",
    "    generation = state_dict[\"generation\"]\n",
    "\n",
    "    # LLM\n",
    "    llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing whether an \n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     \n",
    "    Here is the answer:\n",
    "    {generation} \n",
    "\n",
    "    Here is the question: {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    "    )\n",
    "\n",
    "    answer_grader = prompt | llm | JsonOutputParser()\n",
    "    binary_result = answer_grader.invoke({\"question\": question,\"generation\": generation})\n",
    "    grade = binary_result[\"score\"]\n",
    "    \n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: USEFUL---\")\n",
    "        return \"useful\"\n",
    "    else:\n",
    "        print(\"---DECISION: NOT USEFUL---\")\n",
    "        return \"not useful\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cd2f95-5558-46b3-947f-539cc3333cdb",
   "metadata": {},
   "source": [
    "## Build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18ecbb35-0e3c-4847-abe7-32e4544b688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(AlphaRagState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
    "workflow.add_node(\"prepare_for_final_grade\", prepare_for_final_grade)  # passthrough\n",
    "\n",
    "# Build graph\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    decide_generation_is_grounded_in_documents,\n",
    "    {\n",
    "        \"grounded\": \"prepare_for_final_grade\",\n",
    "        \"not grounded\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"prepare_for_final_grade\",\n",
    "    decide_generation_addresses_question,\n",
    "    {\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"transform_query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9783d78-5a8e-4cbf-8f43-03e8a3d235b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- RETRIEVING DOCUMENTS --\n",
      "State:  {'keys': {'question': 'Generate alpha information based on flow of funds strategy. (Example of alpha information: \\n((rank(Sign(delta(IndNeutralize(((open * 0.868128) + (high * (1 - 0.868128))),\\nIndClass.industry), 4.04545)))^Ts_Rank(correlation(high, adv10, 5.11456), 5.53756)) * -1)\\n)'}}\n",
      "'Finished running: retrieve'\n",
      "---CHECKING RELEVANCE---\n",
      "Score result:  {'score': 'yes'}\n",
      "Grade:  yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "Score result:  {'score': 'yes'}\n",
      "Grade:  yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "Score result:  {'score': 'yes'}\n",
      "Grade:  yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "Score result:  {'score': 'yes'}\n",
      "Grade:  yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "Score result:  {'score': 'yes'}\n",
      "Grade:  yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "Score result:  {'score': 'yes'}\n",
      "Grade:  yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "Score result:  {'score': 'yes'}\n",
      "Grade:  yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "Score result:  {'score': 'yes'}\n",
      "Grade:  yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "Score result:  {'score': 'yes'}\n",
      "Grade:  yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "Score result:  {'score': 'yes'}\n",
      "Grade:  yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "Score result:  {'score': 'yes'}\n",
      "Grade:  yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "Score result:  {'score': 'yes'}\n",
      "Grade:  yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "Score result:  {'score': 'yes'}\n",
      "Grade:  yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "Score result:  {'score': 'yes'}\n",
      "Grade:  yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "Score result:  {'score': 'yes'}\n",
      "Grade:  yes\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---DECIDE TO GENERATE OR TRANSFORM QUERY---\n",
      "---DECISION: GENERATE---\n",
      "'Finished running: grade_documents'\n",
      "---GENERATE---\n",
      "Documents in context:  [Document(page_content='A.1. Formulaic Expressions for Alphas \\nAlpha#1:  (rank(Ts_ArgMax(SignedPower(((returns < 0) ? stdde v(returns, 20) : close), 2.), 5)) - \\n0.5) \\nAlpha#2:  (-1 * correlation(rank(delta(log(volume), 2)), ran k(((close - open) / open)), 6)) \\nAlpha#3:  (-1 * correlation(rank(open), rank(volume), 10)) \\nAlpha#4:  (-1 * Ts_Rank(rank(low), 9)) \\nAlpha#5:  (rank((open - (sum(vwap, 10) / 10))) * (-1 * abs(r ank((close - vwap))))) \\nAlpha#6:  (-1 * correlation(open, volume, 10))', metadata={'source': '101-Alpha-Formula.pdf', 'page': 7}), Document(page_content='* 0.96633) + (low * (1 - 0.96633))) - vwap) / (open  - ((high + low) / 2))), 11.4157), 6.72611)) * -1) \\nAlpha#67:  ((rank((high - ts_min(high, 2.14593)))^rank(correl ation(IndNeutralize(vwap, \\nIndClass.sector), IndNeutralize(adv20, IndClass.sub industry), 6.02936))) * -1) \\nAlpha#68:  ((Ts_Rank(correlation(rank(high), rank(adv15), 8.9 1644), 13.9333) < \\nrank(delta(((close * 0.518371) + (low * (1 - 0.5183 71))), 1.06157))) * -1)', metadata={'source': '101-Alpha-Formula.pdf', 'page': 11}), Document(page_content='Alpha#69:  ((rank(ts_max(delta(IndNeutralize(vwap, IndClass.i ndustry), 2.72412), \\n4.79344))^Ts_Rank(correlation(((close * 0.490655) +  (vwap * (1 - 0.490655))), adv20, 4.92416), \\n9.0615)) * -1) \\nAlpha#70:  ((rank(delta(vwap, 1.29456))^Ts_Rank(correlation(I ndNeutralize(close, \\nIndClass.industry), adv50, 17.8256), 17.9171)) * -1 ) \\nAlpha#71:  max(Ts_Rank(decay_linear(correlation(Ts_Rank(close , 3.43976), Ts_Rank(adv180,', metadata={'source': '101-Alpha-Formula.pdf', 'page': 11}), Document(page_content='12 \\n Alpha#61:  (rank((vwap - ts_min(vwap, 16.1219))) < rank(corre lation(vwap, adv180, 17.9282))) \\nAlpha#62:  ((rank(correlation(vwap, sum(adv20, 22.4101), 9.91 009)) < rank(((rank(open) + \\nrank(open)) < (rank(((high + low) / 2)) + rank(high ))))) * -1) \\nAlpha#63:  ((rank(decay_linear(delta(IndNeutralize(close, Ind Class.industry), 2.25164), 8.22237)) \\n- rank(decay_linear(correlation(((vwap * 0.318108) + (open * (1 - 0.318108))), sum(adv180, \\n37.2467), 13.557), 12.2883))) * -1)', metadata={'source': '101-Alpha-Formula.pdf', 'page': 11}), Document(page_content='14 \\n Alpha#87:  (max(rank(decay_linear(delta(((close * 0.369701) +  (vwap * (1 - 0.369701))), \\n1.91233), 2.65461)), Ts_Rank(decay_linear(abs(corre lation(IndNeutralize(adv81, \\nIndClass.industry), close, 13.4132)), 4.89768), 14. 4535)) * -1) \\nAlpha#88:  min(rank(decay_linear(((rank(open) + rank(low)) - (rank(high) + rank(close))), \\n8.06882)), Ts_Rank(decay_linear(correlation(Ts_Rank (close, 8.44728), Ts_Rank(adv60, \\n20.6966), 8.01266), 6.65053), 2.61957))', metadata={'source': '101-Alpha-Formula.pdf', 'page': 13}), Document(page_content='- close)))) + (0.73 * rank(Ts_Rank(delay((-1 * retu rns), 6), 5)))) + rank(abs(correlation(vwap, \\nadv20, 6)))) + (0.6 * rank((((sum(close, 200) / 200 ) - open) * (close - open))))) \\nAlpha#37:  (rank(correlation(delay((open - close), 1), close,  200)) + rank((open - close))) \\nAlpha#38:  ((-1 * rank(Ts_Rank(close, 10))) * rank((close / o pen))) \\nAlpha#39:  ((-1 * rank((delta(close, 7) * (1 - rank(decay_lin ear((volume / adv20), 9)))))) * (1 + \\nrank(sum(returns, 250))))', metadata={'source': '101-Alpha-Formula.pdf', 'page': 9}), Document(page_content='Alpha#85:  (rank(correlation(((high * 0.876703) + (close * (1  - 0.876703))), adv30, \\n9.61331))^rank(correlation(Ts_Rank(((high + low) / 2), 3.70596), Ts_Rank(volume, 10.1595), \\n7.11408))) \\nAlpha#86:  ((Ts_Rank(correlation(close, sum(adv20, 14.7444), 6.00049), 20.4195) < rank(((open \\n+ close) - (vwap + open)))) * -1)', metadata={'source': '101-Alpha-Formula.pdf', 'page': 12}), Document(page_content='Alpha#40:  ((-1 * rank(stddev(high, 10))) * correlation(high,  volume, 10)) \\nAlpha#41:  (((high * low)^0.5) - vwap) \\nAlpha#42:  (rank((vwap - close)) / rank((vwap + close))) \\nAlpha#43:  (ts_rank((volume / adv20), 20) * ts_rank((-1 * del ta(close, 7)), 8))', metadata={'source': '101-Alpha-Formula.pdf', 'page': 9}), Document(page_content='Alpha#64:  ((rank(correlation(sum(((open * 0.178404) + (low *  (1 - 0.178404))), 12.7054), \\nsum(adv120, 12.7054), 16.6208)) < rank(delta(((((hi gh + low) / 2) * 0.178404) + (vwap * (1 - \\n0.178404))), 3.69741))) * -1) \\nAlpha#65:  ((rank(correlation(((open * 0.00817205) + (vwap * (1 - 0.00817205))), sum(adv60, \\n8.6911), 6.40374)) < rank((open - ts_min(open, 13.6 35)))) * -1) \\nAlpha#66:  ((rank(decay_linear(delta(vwap, 3.51013), 7.23052) ) + Ts_Rank(decay_linear(((((low', metadata={'source': '101-Alpha-Formula.pdf', 'page': 11}), Document(page_content='IndClass.sector), 1.23438)) < rank(correlation(Ts_R ank(vwap, 3.60973), Ts_Rank(adv150, \\n9.18637), 14.6644))) \\nAlpha#80:  ((rank(Sign(delta(IndNeutralize(((open * 0.868128)  + (high * (1 - 0.868128))), \\nIndClass.industry), 4.04545)))^Ts_Rank(correlation( high, adv10, 5.11456), 5.53756)) * -1) \\nAlpha#81:  ((rank(Log(product(rank((rank(correlation(vwap, su m(adv10, 49.6054), \\n8.47743))^4)), 14.9655))) < rank(correlation(rank(v wap), rank(volume), 5.07914))) * -1)', metadata={'source': '101-Alpha-Formula.pdf', 'page': 12}), Document(page_content='Alpha#82:  (min(rank(decay_linear(delta(open, 1.46063), 14.87 17)), \\nTs_Rank(decay_linear(correlation(IndNeutralize(volu me, IndClass.sector), ((open * 0.634196) + \\n(open * (1 - 0.634196))), 17.4842), 6.92131), 13.42 83)) * -1) \\nAlpha#83:  ((rank(delay(((high - low) / (sum(close, 5) / 5)),  2)) * rank(rank(volume))) / (((high - \\nlow) / (sum(close, 5) / 5)) / (vwap - close))) \\nAlpha#84:  SignedPower(Ts_Rank((vwap - ts_max(vwap, 15.3217)) , 20.7127), delta(close, \\n4.96796))', metadata={'source': '101-Alpha-Formula.pdf', 'page': 12}), Document(page_content='rank(delta(volume, 3))) \\nAlpha#12:  (sign(delta(volume, 1)) * (-1 * delta(close, 1))) \\nAlpha#13:  (-1 * rank(covariance(rank(close), rank(volume), 5 ))) \\nAlpha#14:  ((-1 * rank(delta(returns, 3))) * correlation(open , volume, 10)) \\nAlpha#15:  (-1 * sum(rank(correlation(rank(high), rank(volume ), 3)), 3)) \\nAlpha#16:  (-1 * rank(covariance(rank(high), rank(volume), 5) )) \\nAlpha#17:  (((-1 * rank(ts_rank(close, 10))) * rank(delta(del ta(close, 1), 1))) * \\nrank(ts_rank((volume / adv20), 5)))', metadata={'source': '101-Alpha-Formula.pdf', 'page': 8}), Document(page_content='10 \\n Alpha#25:  rank(((((-1 * returns) * adv20) * vwap) * (high - close))) \\nAlpha#26:  (-1 * ts_max(correlation(ts_rank(volume, 5), ts_ra nk(high, 5), 5), 3)) \\nAlpha#27:  ((0.5 < rank((sum(correlation(rank(volume), rank(v wap), 6), 2) / 2.0))) ? (-1 * 1) : 1) \\nAlpha#28:  scale(((correlation(adv20, low, 5) + ((high + low)  / 2)) - close)) \\nAlpha#29:  (min(product(rank(rank(scale(log(sum(ts_min(rank(r ank((-1 * rank(delta((close - 1),', metadata={'source': '101-Alpha-Formula.pdf', 'page': 9}), Document(page_content='IndClass.industry), volume, 9.74928), 16.398), 3.83 219), 4.8667) - \\nrank(decay_linear(correlation(vwap, adv30, 4.01303) , 2.6809))) * -1) \\nAlpha#92:  min(Ts_Rank(decay_linear(((((high + low) / 2) + cl ose) < (low + open)), 14.7221), \\n18.8683), Ts_Rank(decay_linear(correlation(rank(low ), rank(adv30), 7.58555), 6.94024), \\n6.80584)) \\nAlpha#93:  (Ts_Rank(decay_linear(correlation(IndNeutralize(vw ap, IndClass.industry), adv81,', metadata={'source': '101-Alpha-Formula.pdf', 'page': 13}), Document(page_content='Tulchinsky, I. et al . “Finding Alphas: A Quantitative Approach to Build ing Trading Strategies.” \\nNew York, NY: Wiley, 2015.', metadata={'source': '101-Alpha-Formula.pdf', 'page': 16})]\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Invalid json output: Based on the flow of funds strategy, I can generate alpha information for you. Here are a few examples:\n\nAlpha#66: ((rank(open * 0.00817205 + vwap * (1 - 0.00817205))), sum(adv60, 8.6911), 6.40374)) < rank((open - ts_min(open, 13.6 35)))) * -1)\n\nAlpha#80: ((rank(Sign(delta(IndNeutralize(((open * 0.868128) + (high * (1 - 0.868128))), IndClass.industry), 4.04545)))^Ts_ Rank(correlation(high, adv10, 5.11456), 5.53756)) * -1)\n\nAlpha#81: ((rank(Log(product(rank((rank(correlation(vwap, sum(adv10, 49.6054), 8.47743))^4)), 14.9655))) < rank(correlation(rank(vwap), rank(volume), 5.07914))) * -1)\n\nThese alphas are based on the flow of funds strategy, which involves analyzing the relationships between different financial metrics such as open, high, low, close, volume, and adv (average daily volume). The strategy aims to identify patterns and trends in these metrics that can be used to make informed investment decisions.\n\nPlease note that these alphas are just examples and may not be suitable for actual trading or investment purposes. It's always important to thoroughly backtest and validate any trading strategy before implementing it in live markets.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:66\u001b[0m, in \u001b[0;36mJsonOutputParser.parse_result\u001b[1;34m(self, result, partial)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\utils\\json.py:147\u001b[0m, in \u001b[0;36mparse_json_markdown\u001b[1;34m(json_string, parser)\u001b[0m\n\u001b[0;32m    146\u001b[0m         json_str \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\utils\\json.py:160\u001b[0m, in \u001b[0;36m_parse_json\u001b[1;34m(json_str, parser)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\utils\\json.py:120\u001b[0m, in \u001b[0;36mparse_partial_json\u001b[1;34m(s, strict)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    358\u001b[0m     kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_constant\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_constant\n\u001b[1;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerate alpha information based on flow of funds strategy. (Example of alpha information: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALPHA_EXPRESSION_EXAMPLE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeys\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: query }}\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpprint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFinished running: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:700\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before_nodes, interrupt_after_nodes, debug)\u001b[0m\n\u001b[0;32m    693\u001b[0m done, inflight \u001b[38;5;241m=\u001b[39m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mwait(\n\u001b[0;32m    694\u001b[0m     futures,\n\u001b[0;32m    695\u001b[0m     return_when\u001b[38;5;241m=\u001b[39mconcurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFIRST_EXCEPTION,\n\u001b[0;32m    696\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m    697\u001b[0m )\n\u001b[0;32m    699\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m--> 700\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# combine pending writes from all tasks\u001b[39;00m\n\u001b[0;32m    703\u001b[0m pending_writes \u001b[38;5;241m=\u001b[39m deque[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1102\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(done, inflight, step)\u001b[0m\n\u001b[0;32m   1100\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[1;32m-> 1102\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;66;03m# TODO this is where retry of an entire step would happen\u001b[39;00m\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2499\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2497\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2499\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2500\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2501\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   2502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2503\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2504\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2505\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2506\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3967\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3965\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this runnable synchronously.\"\"\"\u001b[39;00m\n\u001b[0;32m   3966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 3967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3974\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   3975\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3976\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3977\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1625\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1621\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1622\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[0;32m   1623\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1624\u001b[0m         Output,\n\u001b[1;32m-> 1625\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1628\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1629\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1633\u001b[0m     )\n\u001b[0;32m   1634\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1635\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3841\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   3839\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[0;32m   3840\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3841\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3842\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   3843\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3844\u001b[0m \u001b[38;5;66;03m# If the output is a runnable, invoke it\u001b[39;00m\n\u001b[0;32m   3845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 144\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m    141\u001b[0m rag_chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m llm \u001b[38;5;241m|\u001b[39m JsonOutputParser()\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Run\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m generation \u001b[38;5;241m=\u001b[39m \u001b[43mrag_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mformatted_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlist_of_alpha_numbers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_of_alpha_numbers\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated response to alpha query: \u001b[39m\u001b[38;5;124m\"\u001b[39m, generation)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeys\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m: documents, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m: generation}\n\u001b[0;32m    149\u001b[0m }\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2499\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2497\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2499\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2500\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2501\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   2502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2503\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2504\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2505\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2506\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:169\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage], config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    167\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[1;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[0;32m    180\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    181\u001b[0m             config,\n\u001b[0;32m    182\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    183\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1625\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1621\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1622\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[0;32m   1623\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1624\u001b[0m         Output,\n\u001b[1;32m-> 1625\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1628\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1629\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1633\u001b[0m     )\n\u001b[0;32m   1634\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1635\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:170\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[1;34m(inner_input)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage], config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    167\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m--> 170\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    173\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    174\u001b[0m             config,\n\u001b[0;32m    175\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    176\u001b[0m         )\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[0;32m    180\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    181\u001b[0m             config,\n\u001b[0;32m    182\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    183\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:69\u001b[0m, in \u001b[0;36mJsonOutputParser.parse_result\u001b[1;34m(self, result, partial)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     68\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid json output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output\u001b[38;5;241m=\u001b[39mtext) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Invalid json output: Based on the flow of funds strategy, I can generate alpha information for you. Here are a few examples:\n\nAlpha#66: ((rank(open * 0.00817205 + vwap * (1 - 0.00817205))), sum(adv60, 8.6911), 6.40374)) < rank((open - ts_min(open, 13.6 35)))) * -1)\n\nAlpha#80: ((rank(Sign(delta(IndNeutralize(((open * 0.868128) + (high * (1 - 0.868128))), IndClass.industry), 4.04545)))^Ts_ Rank(correlation(high, adv10, 5.11456), 5.53756)) * -1)\n\nAlpha#81: ((rank(Log(product(rank((rank(correlation(vwap, sum(adv10, 49.6054), 8.47743))^4)), 14.9655))) < rank(correlation(rank(vwap), rank(volume), 5.07914))) * -1)\n\nThese alphas are based on the flow of funds strategy, which involves analyzing the relationships between different financial metrics such as open, high, low, close, volume, and adv (average daily volume). The strategy aims to identify patterns and trends in these metrics that can be used to make informed investment decisions.\n\nPlease note that these alphas are just examples and may not be suitable for actual trading or investment purposes. It's always important to thoroughly backtest and validate any trading strategy before implementing it in live markets."
     ]
    }
   ],
   "source": [
    "# Test\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "from pprint import pprint\n",
    "\n",
    "ALPHA_EXPRESSION_EXAMPLE = \"\"\"\n",
    "((rank(Sign(delta(IndNeutralize(((open * 0.868128) + (high * (1 - 0.868128))),\n",
    "IndClass.industry), 4.04545)))^Ts_Rank(correlation(high, adv10, 5.11456), 5.53756)) * -1)\n",
    "\"\"\"\n",
    "query = f\"Generate alpha information based on flow of funds strategy. (Example of alpha information: {ALPHA_EXPRESSION_EXAMPLE})\"\n",
    "\n",
    "inputs = {\"keys\": {\"question\": query }}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Finished running: {key}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Elpased time: {end - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7e67b3-9453-4daa-916c-c9d030895dd3",
   "metadata": {},
   "source": [
    "__Wrong example gotten without few shot examples__\n",
    "1. Generated response to alpha query:  [{'alpha_expression': 'Flow of Funds Alpha', 'explanation': 'The Flow of Funds Alpha strategy involves analyzing the movement of funds between different asset classes, sectors, or industries to identify trends and patterns. This approach can help identify alpha opportunities by capturing changes in investor sentiment, market conditions, and economic indicators.'}].\n",
    "   \n",
    "__Generation example after passing few shot examples without few shot examples__(Gave generic explanation of flow of fund strategy instead of `providing explanation to alpha expression`)\n",
    "3. Generated response to alpha query:  [{'alpha_expression': '-1 * rank(decay_linear(volume / adv20), 9)) * (1 + rank(sum(returns, 250)))', 'explanation': 'The flow of funds strategy is based on the idea that the movement of money in and out of a portfolio can be a valuable indicator of future stock performance. By analyzing the volume data and smoothing it out using the `decay_linear` function, we can create a signal that captures the momentum of the market.'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6021cd7-8d7f-41ed-baec-8eb900bb144e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
